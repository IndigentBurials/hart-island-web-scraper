{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hart Island Web-scraper\n",
    "----\n",
    "\n",
    "**Author:** Simon Aytes\n",
    "\n",
    "**Contact:** simon.aytes@lc.cuny.edu\n",
    "\n",
    "**Version:** 1.0\n",
    "\n",
    "**Date:** August 21, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment Configuration\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.common.exceptions import NoSuchElementException      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exists_by_xpath(xpath):\n",
    "    try:\n",
    "        webdriver.find_element(By.XPATH, xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_obj(user_date):\n",
    "    temp = user_date.split(\"/\")\n",
    "    date = datetime(int(temp[2]), int(temp[0]), int(temp[1]))\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_date_form(driver, date_str):\n",
    "    # Fill form with date range\n",
    "    dateDeathFrom = driver.find_element(By.XPATH,\"//*[@id='home_form:date_death_from_input']\")\n",
    "    dateDeathFrom.clear()\n",
    "    dateDeathFrom.send_keys(date_str)\n",
    "    dateDeathTo = driver.find_element(By.XPATH,\"//*[@id='home_form:date_death_to_input']\")\n",
    "    dateDeathTo.clear()\n",
    "    dateDeathTo.send_keys(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_gender_option(driver, gender_index):\n",
    "    gender_dropdown = driver.find_element(By.XPATH, \"//*[@id='home_form:gender_input']\")\n",
    "    gender_dropdown = Select(gender_dropdown)\n",
    "    gender_dropdown.select_by_index(gender_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_contents(driver, n_cols):\n",
    "    row_contents = []\n",
    "    for p in range(1, n_cols+1):\n",
    "        # obtaining the text from each column of the table\n",
    "        value = driver.find_element(By.XPATH, \"//*[@id='search_result_table']/tbody/tr[\"+str(r)+\"]/td[\"+str(p)+\"]\").text\n",
    "        row_contents.append(value)\n",
    "    return row_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_webdriver():\n",
    "    # Setup Chrome webdriver\n",
    "    cd_service = Service(\"./chromedriver/chromedriver\")\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=cd_service, options=options)\n",
    "    \n",
    "    # Return the driver object\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrement_date(date, days_to_subtract):\n",
    "    return (date - timedelta(days = days_to_subtract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_string(date):\n",
    "    return date.strftime(\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scrape Data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TIME: 3:33PM EST\n",
    "# END TIME: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Date From (older date, MM/DD/YYYY):  05/10/2020\n",
      "Date To (most-recent date, MM/DD/YYYY):  05/15/2020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURR DATE: 2020-05-16 00:00:00\n",
      "FROM DATE: 2020-05-10 00:00:00\n",
      "TO DATE: 2020-05-15 00:00:00\n",
      "Scraping data...\n",
      "\t\t> 05/15/2020\n",
      "\t\t\t> MALE\n",
      "\t\t\t> FEMALE\n",
      "\t\t\t> UNKNOWN\n",
      "\t\t> 05/14/2020\n",
      "\t\t\t> MALE\n",
      "\t\t\t> FEMALE\n",
      "\t\t\t> UNKNOWN\n",
      "\t\t> 05/13/2020\n",
      "\t\t\t> MALE\n",
      "\t\t\t> FEMALE\n",
      "\t\t\t> UNKNOWN\n",
      "\t\t> 05/12/2020\n",
      "\t\t\t> MALE\n",
      "\t\t\t> FEMALE\n",
      "\t\t\t> UNKNOWN\n",
      "\t\t> 05/11/2020\n",
      "\t\t\t> MALE\n",
      "\t\t\t> FEMALE\n",
      "\t\t\t> UNKNOWN\n",
      "\t\t> 05/10/2020\n",
      "\t\t\t> MALE\n",
      "\t\t\t> FEMALE\n",
      "\t\t\t> UNKNOWN\n",
      "Done collecting data!\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "f_names = []\n",
    "l_names = []\n",
    "ages = []\n",
    "sexes = []\n",
    "date_of_deaths = []\n",
    "place_of_deaths = []\n",
    "plot_no = []\n",
    "medical_examiner_nos = []\n",
    "urls = []\n",
    "date_scraped = []\n",
    "jurisdiction = []\n",
    "\n",
    "# Define loop variables\n",
    "sleep_seconds = 1\n",
    "\n",
    "# Dropdown options as dict (Format -- {Label:XPath})\n",
    "gender_opt_list = {'MALE':1, 'FEMALE':2, 'UNKNOWN':3}\n",
    "\n",
    "# Create list of dates with no records\n",
    "female_no_record_dates = []\n",
    "male_no_record_dates = []\n",
    "unknown_no_record_dates = []\n",
    "\n",
    "# Create list of dates with 30 or more records\n",
    "thirty_or_more_record_dates = []\n",
    "\n",
    "# Get input for from- and to- dates\n",
    "from_date = get_date_obj(input(\"Date From (older date, MM/DD/YYYY): \"))\n",
    "to_date = get_date_obj(input(\"Date To (most-recent date, MM/DD/YYYY): \"))\n",
    "curr_date = to_date + timedelta(days=1) # Add one to the start date because of loop structure\n",
    "print(f\"CURR DATE: {curr_date}\\nFROM DATE: {from_date}\\nTO DATE: {to_date}\")\n",
    "print(\"Scraping data...\")\n",
    "\n",
    "# Create the webdriver\n",
    "driver = create_webdriver()\n",
    "\n",
    "# Make the window larger\n",
    "driver.maximize_window()\n",
    "\n",
    "# Initialize date flag\n",
    "date_flag = False\n",
    "\n",
    "while date_flag == False:\n",
    "    # Check if the current date being scraped is out of bounds\n",
    "    if curr_date <= from_date:\n",
    "        date_flag = True\n",
    "        break\n",
    "    \n",
    "    # Calculate new date range by subtracting one day\n",
    "    #curr_date = curr_date - timedelta(days=1)\n",
    "    curr_date = decrement_date(curr_date, 1)\n",
    "    \n",
    "    # Get the date string to be input into the box on the page\n",
    "    curr_date_str = get_date_string(curr_date)\n",
    "    \n",
    "    print(f\"\\t\\t> {curr_date_str}\")\n",
    "    \n",
    "    # Loop through all dropdown values (MALE, FEMALE, UNKNOWN)\n",
    "    for gender in gender_opt_list:\n",
    "        # Try to gather the data. If any errors are thrown, see 'except' block below.\n",
    "        try:\n",
    "            print(f\"\\t\\t\\t> {gender}\")\n",
    "            # Establish the website's address\n",
    "            url = \"https://a073-hartisland-web.nyc.gov/hartisland/pages/home/home.jsf\"\n",
    "\n",
    "            # Open website\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for 'n' seconds\n",
    "            sleep(sleep_seconds)\n",
    "            \n",
    "            # Fill form with date range\n",
    "            fill_date_form(driver, curr_date_str)\n",
    "            \n",
    "            # Select the gender option by clicking directly to the option's XPATH\n",
    "            select_gender_option(driver, gender_opt_list[gender])\n",
    "            \n",
    "            # Submit the form and load new page\n",
    "            driver.find_element(By.XPATH,\"//*[@id='home_form:search_lk']\").click()\n",
    "            sleep(sleep_seconds)\n",
    "\n",
    "            # Obtains number of rows and columns\n",
    "            rows = 1+len(driver.find_elements(By.XPATH, \"//*[@id='search_result_table']/tbody/tr\"))\n",
    "            cols = len(driver.find_elements(By.XPATH, \"//*[@id='search_result_table']/tbody/tr[1]/td\"))\n",
    "\n",
    "            # Check if there are more than thirty records on a given date. If so, flag it\n",
    "            if rows - 1 >= 30:\n",
    "                thirty_or_more_record_dates.append(curr_date_str)\n",
    "\n",
    "            # Gather the contents of table row-by-row\n",
    "            for r in range(1, rows):\n",
    "                # Get the contents of the row\n",
    "                row_contents = get_row_contents(driver, cols)\n",
    "                \n",
    "                # Append values to lists\n",
    "                f_names.append(row_contents[1])\n",
    "                l_names.append(row_contents[0])\n",
    "                ages.append(row_contents[2])\n",
    "                sexes.append(gender)\n",
    "                date_of_deaths.append(row_contents[3])\n",
    "                place_of_deaths.append(row_contents[4])\n",
    "                plot_no.append(row_contents[5])\n",
    "                medical_examiner_nos.append(row_contents[6])\n",
    "                urls.append(url)\n",
    "                date_scraped.append(datetime.now().strftime(\"%m/%d/%Y\"))\n",
    "                jurisdiction.append(\"Hart Island\")\n",
    "\n",
    "            # Return to search\n",
    "            driver.find_element(By.XPATH,\"//*[@id='home_form:j_id_9b']\").click()\n",
    "            \n",
    "        # If there is an error, it means there were no records on that date for that specified gender. Log it here and move on to next.\n",
    "        except Exception as e:\n",
    "            #print(f\"\\t> No records present for {curr_date_str}...\") # Log the date with no record, DEBUG\n",
    "            # Log the dates with no records\n",
    "            if gender == \"MALE\":\n",
    "                male_no_record_dates.append(curr_date_str)\n",
    "            elif gender == \"FEMALE\":\n",
    "                female_no_record_dates.append(curr_date_str)\n",
    "            elif gender == \"UNKNOWN\":\n",
    "                unknown_no_record_dates.append(curr_date_str)\n",
    "            # Continue to next loop\n",
    "            continue\n",
    "\n",
    "# When the data is gathered, close the window and log message.\n",
    "driver.quit() # Close the ChromeDriver window\n",
    "print(\"Done collecting data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Output Data to CSV\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dataframe with results\n",
    "data = pd.DataFrame()\n",
    "data['FName'] = f_names\n",
    "data['LName'] = l_names\n",
    "data['Age'] = ages\n",
    "data['Sex'] = sexes\n",
    "data['DOD'] = date_of_deaths\n",
    "data['POD'] = place_of_deaths\n",
    "data['PlotNo'] = plot_no\n",
    "data['CaseNo'] = medical_examiner_nos\n",
    "data['Jurisdiction'] = jurisdiction\n",
    "data['DateScraped'] = date_scraped\n",
    "data['SourceURL'] = urls\n",
    "file_name = './data/DOC_' + str(datetime.now().strftime('%Y-%m-%d_%H:%M:%S')) + '.csv'\n",
    "data.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 3 days without records.\n",
      "Total of 0 with more than 30 records.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of {len(no_record_dates)} days without records.\\nTotal of {len(thirty_or_more_record_dates)} with more than 30 records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gathered a total of XX results between DAY-1 and DAY-2. Complete runtime was HH:MM:SS, amounting to an average of TIME UNIT per day of gathered data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
